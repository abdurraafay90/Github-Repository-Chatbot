ğŸ§  GitHub Repository Chatbot

A conversational GitHub repository assistant built using LangChain, OpenAI, and Chainlit.
Simply paste a public GitHub repo link, and the chatbot will fetch all readable files, build embeddings, and let you ask questions about the repositoryâ€™s code, documentation, or structure â€” just like ChatGPT for GitHub!

ğŸš€ Features

ğŸ”— Accepts any public GitHub repository link

ğŸ“‚ Automatically fetches all .py, .js, .html, .css, .md, and .txt files

ğŸ§© Splits and processes repository content using LangChain Text Splitters

ğŸ§® Embeds file chunks using text-embedding-3-small

ğŸ§  Stores embeddings in a local FAISS vectorstore

ğŸ’¬ Answers user queries contextually using OpenAI GPT models

âš¡ Streams responses live via Chainlit chat interface

ğŸ” Simple, modular, and extensible pipeline â€” perfect for experimenting with RAG

ğŸ§° Tech Stack
Component	Library
Framework	Chainlit

LLM	OpenAI GPT (via LangChain)

Embeddings	text-embedding-3-small
Vector Store	FAISS

Repo Fetching	requests (GitHub REST API)
Environment	.env for API keys
âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the repository
```
git clone https://github.com/your-username/github-chatbot.git
```
```
cd github-chatbot
```

2ï¸âƒ£ Create a virtual environment
```
python -m venv .venv
```
```
.\.venv\Scripts\activate
```

3ï¸âƒ£ Install dependencies

ğŸ§© Option 1 â€” Using pip
```
pip install -r requirements.txt
```

âš¡ Option 2 â€” Using uv (recommended)
```
uv pip install -r requirements.txt
```
4ï¸âƒ£ Set up environment variables

Create a .env file in your project root directory and add your OpenAI API key:

```
OPENAI_API_KEY=your_openai_api_key_here
```
5ï¸âƒ£ Run the chatbot

ğŸ§  Using uv (recommended)
```
uv run chainlit run app.py
```

ğŸ Or using Python directly
```
chainlit run app.py
```

Once the server starts, open the provided local URL in your browser â€”
your GitHub Repository Chatbot will be live! ğŸ‰

ğŸ§  How It Works

You provide a GitHub repo link.

The app fetches all code and text files via the GitHub API.

LangChain splits each file into smaller, meaningful chunks.

Each chunk is embedded using OpenAI embeddings and stored in FAISS.

When you ask a question, the app retrieves the most relevant chunks.

OpenAI GPT generates a context-aware answer in real-time.

ğŸ“œ License

This project is licensed under the MIT License â€”
youâ€™re free to use, modify, and distribute it with attribution.
